{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37a089-17f2-41ca-9db2-a6dbf9b223a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/gmshroff/algostrats.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b78587-dfff-4fb8-82e4-28a956965910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd algostrats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ae655-3710-499c-9d31-d64bfbd7607e",
   "metadata": {},
   "source": [
    "Uncomment below if on Colab and using datasets from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad16195-568c-44f0-9c1f-01e446ea89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0334f4-4128-4cc7-8fe1-b313b99f225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /root/.kaggle\n",
    "# !mv ./kaggle.json /root/.kaggle/.\n",
    "# !chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59924910-e649-4161-9fda-f8d85c5cb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir data\n",
    "# %cd data\n",
    "# !kaggle datasets download -d gmshroff/marketdatafivemin\n",
    "# %cd ../algostrats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b845872c-48f2-4622-9925-9246e444570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab=False\n",
    "script=False\n",
    "if not colab: \n",
    "    DATAPATH='../algodata'\n",
    "elif colab: DATAPATH='../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104b582-d222-4e95-8b2d-cb28f63c014f",
   "metadata": {},
   "source": [
    "Need to import algorithms from stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490b5786-dc7a-4403-bfc6-9f5934ddcd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishabh/miniforge3/envs/metarl/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO,A2C,DQN\n",
    "from stable_baselines3.common.vec_env import StackedObservations\n",
    "from stable_baselines3.common.monitor import Monitor as Mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee07310c-dd1c-4d26-b301-d329a01cd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7889ded-dd8c-4c73-aadd-687cf98ddbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from datetime import datetime as dt\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from threading import Thread\n",
    "import threading\n",
    "from IPython import display\n",
    "import time,getopt,sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27681588-e85b-4818-b7f9-9e8aca7d87cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from feeds.ipynb\n",
      "importing Jupyter notebook from synfeed.ipynb\n",
      "importing Jupyter notebook from india_calendar.ipynb\n",
      "importing Jupyter notebook from featfuncs.ipynb\n"
     ]
    }
   ],
   "source": [
    "from feeds import BackFeed,DataFeed\n",
    "from featfuncs import feat_aug,add_addl_features_feed,add_ta_features_feed,add_sym_feature_feed\n",
    "from featfuncs import add_global_indices_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da69070-9830-44a9-bd5d-0f9800a0c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from feed_env.ipynb\n"
     ]
    }
   ],
   "source": [
    "from feed_env import Episode\n",
    "import aspectlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf1f9c-6a1b-48c4-a162-db735c649a0f",
   "metadata": {},
   "source": [
    "### Trading strategies as agents\n",
    "\n",
    "RL(++)StratAgents imported from ruleagents<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7097885-4b48-4472-9f28-bde7d73c7c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rlagents.ipynb\n",
      "importing Jupyter notebook from aiagentbase.ipynb\n"
     ]
    }
   ],
   "source": [
    "from rlagents import RLStratAgentDyn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c2614-221c-4490-aa27-ab4e3e12bb5b",
   "metadata": {},
   "source": [
    "### Strategy Development: Training RLStratAgent using BackTestWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db830b3-32e5-4ac4-99e5-f077166076c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from backtest.ipynb\n",
      "importing Jupyter notebook from validation.ipynb\n"
     ]
    }
   ],
   "source": [
    "from backtest import Backtest\n",
    "from feeds import BackFeed,DataFeed\n",
    "from validation import Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d261917-c858-4430-80de-dcaaffb43b71",
   "metadata": {},
   "source": [
    "<b>Configuration for training RL model<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d52550-8d0d-4c51-a135-b353b424c625",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=PPO\n",
    "synthetic=False #use synthetic data\n",
    "simple=False #False,True or 'sinewave'\n",
    "nd,nw=5,4 #for BackFeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9716cf-64ff-49cb-80e6-5867b6f571c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if script:\n",
    "    try:\n",
    "        opts,args = getopt.getopt(sys.argv[1:],\"hl:f:d:m:s:w:t:p:u:\",[\"load=\",\"feed=\",\"datafile=\",\"modelname=\",\"synthetic\",\"weeks\",\"training_steps\",\"deploy\",\"use_alt_data\"])\n",
    "    except getopt.GetoptError:\n",
    "        print('rlagents_train.py -l <load:True/False> -f <scan:back/data> -d <datafile> -m <modelname> -s <synthetic> -w <weeks> -t <training_steps> -p <deploy>')\n",
    "        sys.exit(2)\n",
    "    load,feed,modelname=False,'back',''\n",
    "    training_steps=50000 # if less then n_steps then n_steps is used\n",
    "    deploy=True\n",
    "    date=datetime.today().strftime('%d-%b-%Y')\n",
    "    use_alt_data=False\n",
    "    for opt, arg in opts:\n",
    "        if opt == \"-h\":\n",
    "            print('rlagents_train.py -l <load:True/False> -f <scan:back/data> -d <datafile> -m <modelname> -s <synthetic> -w <weeks> -t <training_steps> -p <deploy> -u <use_alt_data>')\n",
    "            sys.exit()\n",
    "        elif opt in (\"-l\", \"--load\"):\n",
    "            load = (lambda x: True if x=='True' else False)(arg)\n",
    "        elif opt in (\"-f\", \"--feed\"):\n",
    "            feed = (lambda x: 'data' if x=='data' else 'back')(arg)\n",
    "        elif opt in (\"-d\", \"--datafile\"):\n",
    "            datafile = arg.split('/')[-1]\n",
    "        elif opt in (\"-m\", \"--modelname\"):\n",
    "            modelname = arg\n",
    "        elif opt in (\"-s\", \"--synthetic\"):\n",
    "            synthetic = (lambda x: True if x=='True' else False)(arg)\n",
    "        elif opt in (\"-w\", \"--weeks\"):\n",
    "            nw = int(arg)\n",
    "        elif opt in (\"-t\", \"--training_steps\"):\n",
    "            training_steps=int(arg)\n",
    "        elif opt in (\"-p\", \"--deploy\"):\n",
    "            deploy = (lambda x: True if x=='True' else False)(arg)\n",
    "        elif opt in (\"-u\", \"--use_alt_data\"):\n",
    "            use_alt_data = (lambda x: True if x=='True' else False)(arg)\n",
    "    if len(opts)==0: \n",
    "        print('rlagents_train.py -l <load:True/False> -f <scan:back/data> -d <datafile> -m <modelname> -s <synthetic> -w <weeks> -t <training_steps> -p <deploy> -u <use_alt_data>')\n",
    "        sys.exit()\n",
    "    print(f\"load:{load},feed:{feed},datafile:{datafile},modelname:{modelname},synthetic:{synthetic},weeks:{nw},training_steps:{training_steps},deploy:{deploy},use_alt_data:{use_alt_data}\")\n",
    "    loadfeed=load\n",
    "    if feed=='data': datafeed=True\n",
    "    else: datafeed=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf60db39-56f0-4a19-9874-6a75e04a82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not script:\n",
    "    loadfeed=False\n",
    "    datafeed=True\n",
    "    datafile='/realdata/augdata_02-May-2022_5m.csv'\n",
    "    modelname= 'realdata_may.pth'\n",
    "    # modelname='SINE1.pth' # replace with modelname if model to be saved to saved_models\n",
    "    # modelname='RLG0.pth'\n",
    "    date=datetime.today().strftime('%d-%b-%Y')\n",
    "    training_steps=50000 # if less then n_steps then n_steps is used\n",
    "    deploy=True\n",
    "    use_alt_data=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af987410-4258-4ad4-adb0-ac8cba49e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=2048 # reduce for debugging only else 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a30cb1c-323b-49a4-a835-b725c0d2cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(x):\n",
    "    return pd.to_datetime(x['Datetime']).strftime('%d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0742b6ae-da3c-4d24-a392-762ca2433314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if not loadfeed and not datafeed:\n",
    "    data=pd.read_csv('./capvol100.csv')\n",
    "    tickers=list(data.iloc[0:50]['ticker'].values)\n",
    "    print('Creating feed')\n",
    "    feed=BackFeed(tickers=tickers,nd=nd,nw=nw,interval='5m',synthetic=synthetic,simple=simple)\n",
    "    print('Processing feed')\n",
    "    # add_addl_features_feed(feed,tickers=feed.tickers)\n",
    "    # add_sym_feature_feed(feed,tickers=feed.tickers)\n",
    "    if not synthetic: add_global_indices_feed(feed)\n",
    "    if not colab: \n",
    "        with open('../algodata/btfeed.pickle','wb') as f: pickle.dump(feed,f)\n",
    "    elif colab: \n",
    "        with open('/tmp/btfeed.pickle','wb') as f: pickle.dump(feed,f)\n",
    "        \n",
    "        \n",
    "elif loadfeed and not datafeed:\n",
    "    if not colab: \n",
    "        with open('../../temp_data/btfeed.pickle','rb') as f: feed=pickle.load(f)\n",
    "    elif colab: \n",
    "        with open('/tmp/btfeed.pickle','rb') as f: feed=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e98851e-d7ed-4c7a-89ff-5382091368cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading datafile\n",
      "Adding Date\n",
      "Creating feed\n",
      "Processing feed\n"
     ]
    }
   ],
   "source": [
    "if not loadfeed and datafeed:\n",
    "    DATAFILE=DATAPATH+datafile\n",
    "    print('Reading datafile')\n",
    "    df=pd.read_csv(DATAFILE)\n",
    "    if 'Date' not in df.columns: \n",
    "        print('Adding Date')\n",
    "        df['Date']=df.apply(stringify,axis=1)\n",
    "    print('Creating feed')\n",
    "    feed=DataFeed(tickers=list(df.ticker.unique()[0:10]),dfgiven=True,df=df)\n",
    "    print('Processing feed')\n",
    "    add_addl_features_feed(feed,tickers=feed.tickers)\n",
    "    add_sym_feature_feed(feed,tickers=feed.tickers)\n",
    "    # add_global_indices_feed(feed)\n",
    "    if not colab: \n",
    "        with open('../algodata/btdatafeed.pickle','wb') as f: pickle.dump(feed,f)\n",
    "    elif colab: \n",
    "        with open('/tmp/btdatafeed.pickle','wb') as f: pickle.dump(feed,f)\n",
    "elif loadfeed and datafeed:\n",
    "    if not colab: \n",
    "        with open('../../temp_data/btdatafeed.pickle','rb') as f: feed=pickle.load(f)\n",
    "    elif colab:\n",
    "        with open('/tmp/btdatafeed.pickle','rb') as f: feed=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45eacf64-c0fe-4290-a489-fcd10353aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alt_data_live():\n",
    "    aD={'gdata':feed.gdata}\n",
    "    return aD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51966e37-f9c0-4a59-965e-c5b9a1bef3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "agent=RLStratAgentDyn(algorithm,monclass=Mon,soclass=StackedObservations,verbose=1,win=5,\n",
    "                   metarl=True,myargs=(n_steps,use_alt_data))\n",
    "agent.use_memory=True #depends on whether RL algorithm uses memory for state computation\n",
    "agent.debug=False\n",
    "if use_alt_data: agent.set_alt_data(alt_data_func=get_alt_data_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e84d5950-660a-476b-8a08-12a367b45d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if modelname and os.path.exists('./saved_models/'+modelname): \n",
    "    agent.load_model(filepath='./saved_models/'+modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa113224-1c19-431f-a01e-f1f42d17bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@aspectlib.Aspect\n",
    "def my_decorator(*args, **kwargs):\n",
    "    # print(\"Got called with args: %s kwargs: %s\" % (args, kwargs))\n",
    "    # result = yield\n",
    "    # print(\" ... and the result is: %s\" % (result,))\n",
    "    state,rew,done,exit_type = yield\n",
    "    # args[0].policy.logL+=[(state.keys(),rew,done,exit_type)]\n",
    "    args[0].policy.reward((rew,done,{'exit_type':exit_type}))\n",
    "    return state,rew,done,exit_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50fa58e2-3bd9-475c-ad0d-df1d70b4f49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aspectlib.Rollback at 0x15c5a7070>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspectlib.weave(Episode, my_decorator, methods='env_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fde12ee-eb14-4405-8e41-0a7ce44f132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt=Backtest(feed,tickers=feed.tickers,add_features=True,target=5,stop=5,txcost=0.001,\n",
    "            loc_exit=True,scan=True,topk=5,deploy=deploy,save_dfs=False,\n",
    "            save_func=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ba114e0-b1c0-4e12-b32b-605b93eda1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.data_cols=agent.data_cols+['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34a612fb-f44e-4319-8972-5545088dd780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_btworld():\n",
    "    global bt,feed,agent\n",
    "    while agent.training:\n",
    "        bt.run_all(tickers=feed.tickers,model=agent,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4bdb8f1-d284-4916-91f6-d81f90ef11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.start(training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6db2a58-86ab-4035-a6fb-2664bd567f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "btworldthread=Thread(target=run_btworld,name='btworld')\n",
    "btworldthread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9bf213b-0c01-4728-a1e3-22d8dfdf8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bt_training_status():\n",
    "    threadL=[thread.name for thread in threading.enumerate()]\n",
    "    # print(threadL)\n",
    "    if 'monitor' not in threadL and 'btworld' not in threadL:\n",
    "        print(f'Training Over after {agent.model.num_timesteps} steps')\n",
    "        return False\n",
    "    else:\n",
    "        print(f'Model Training for {agent.model.num_timesteps} steps')\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb88e3c0-ec74-4955-8bcb-c923b364ae69",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training for 368 steps\n",
      "Model Training for 728 steps\n",
      "Model Training for 1127 steps\n",
      "Model Training for 1520 steps\n",
      "Model Training for 1910 steps\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.62     |\n",
      "|    ep_rew_mean     | -0.552   |\n",
      "| time/              |          |\n",
      "|    fps             | 176      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "Model Training for 2060 steps\n",
      "Model Training for 2468 steps\n",
      "Model Training for 2864 steps\n",
      "Model Training for 3222 steps\n",
      "Model Training for 3587 steps\n",
      "Model Training for 3995 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.95        |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 175         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011733718 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | -0.0561     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 2.92        |\n",
      "-----------------------------------------\n",
      "Model Training for 4156 steps\n",
      "Model Training for 4500 steps\n",
      "Model Training for 4850 steps\n",
      "Model Training for 5223 steps\n",
      "Model Training for 5618 steps\n",
      "Model Training for 5973 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.44        |\n",
      "|    ep_rew_mean          | -0.301      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010001982 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | -0.0132     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 2.81        |\n",
      "-----------------------------------------\n",
      "Model Training for 6158 steps\n",
      "Model Training for 6534 steps\n",
      "Model Training for 6920 steps\n",
      "Model Training for 7258 steps\n",
      "Model Training for 7633 steps\n",
      "Model Training for 8005 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.4         |\n",
      "|    ep_rew_mean          | 0.0561      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 171         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014538456 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | -0.0163     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 3.07        |\n",
      "-----------------------------------------\n",
      "Model Training for 8194 steps\n",
      "Model Training for 8581 steps\n",
      "Model Training for 8908 steps\n",
      "Model Training for 9225 steps\n",
      "Model Training for 9547 steps\n",
      "Model Training for 9899 steps\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.47       |\n",
      "|    ep_rew_mean          | 0.185      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 168        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01122021 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.19      |\n",
      "|    explained_variance   | -0.0186    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.1        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 2.7        |\n",
      "----------------------------------------\n",
      "Model Training for 10240 steps\n",
      "Model Training for 10447 steps\n",
      "Model Training for 10783 steps\n",
      "Model Training for 11145 steps\n",
      "Model Training for 11479 steps\n",
      "Model Training for 11836 steps\n",
      "Model Training for 12177 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.25        |\n",
      "|    ep_rew_mean          | 0.248       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012100412 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 1.9e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "Model Training for 12314 steps\n",
      "Model Training for 12647 steps\n",
      "Model Training for 13034 steps\n",
      "Model Training for 13352 steps\n",
      "Model Training for 13685 steps\n",
      "Model Training for 14033 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.3         |\n",
      "|    ep_rew_mean          | -0.0357     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 165         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010400662 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | -0.00492    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.562       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "Model Training for 14336 steps\n",
      "Model Training for 14559 steps\n",
      "Model Training for 14912 steps\n",
      "Model Training for 15235 steps\n",
      "Model Training for 15589 steps\n",
      "Model Training for 15952 steps\n",
      "Model Training for 16315 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.26        |\n",
      "|    ep_rew_mean          | 0.314       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 164         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011437496 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.00942     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "Model Training for 16479 steps\n",
      "Model Training for 16810 steps\n",
      "Model Training for 17155 steps\n",
      "Model Training for 17479 steps\n",
      "Model Training for 17806 steps\n",
      "Model Training for 18120 steps\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.86         |\n",
      "|    ep_rew_mean          | 0.191        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 162          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118867345 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.01        |\n",
      "|    explained_variance   | -0.00748     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    value_loss           | 2.31         |\n",
      "------------------------------------------\n",
      "Model Training for 18432 steps\n",
      "Model Training for 18561 steps\n",
      "Model Training for 18864 steps\n",
      "Model Training for 19111 steps\n",
      "Model Training for 19406 steps\n",
      "Model Training for 19700 steps\n",
      "Model Training for 20023 steps\n",
      "Model Training for 20305 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.9         |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011471123 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.8         |\n",
      "-----------------------------------------\n",
      "Model Training for 20480 steps\n",
      "Model Training for 20751 steps\n",
      "Model Training for 21046 steps\n",
      "Model Training for 21358 steps\n",
      "Model Training for 21641 steps\n",
      "Model Training for 21967 steps\n",
      "Model Training for 22303 steps\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.66        |\n",
      "|    ep_rew_mean          | -0.0338     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011786307 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "Model Training for 22528 steps\n",
      "Model Training for 22767 steps\n",
      "Model Training for 23080 steps\n",
      "Model Training for 23366 steps\n",
      "Model Training for 23722 steps\n",
      "Model Training for 24081 steps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwhile\u001b[39;00m check_bt_training_status():\n\u001b[0;32m----> 2\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.94        |\n",
      "|    ep_rew_mean          | 0.224       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013813192 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.0289      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.904       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 2.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.12        |\n",
      "|    ep_rew_mean          | 0.275       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010577016 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.927       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.19        |\n",
      "|    ep_rew_mean          | -0.0128     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011035149 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.6          |\n",
      "|    ep_rew_mean          | 0.0634       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123842005 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0375       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.938        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    value_loss           | 2.29         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | 0.442       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011773121 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.991       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.49        |\n",
      "|    ep_rew_mean          | 0.531       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013497212 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    value_loss           | 2.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.75        |\n",
      "|    ep_rew_mean          | 0.425       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014749306 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.0624      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    value_loss           | 2.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.51        |\n",
      "|    ep_rew_mean          | 0.262       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014404779 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.0809      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.973       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 2.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.16        |\n",
      "|    ep_rew_mean          | 0.393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012160329 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.0974      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.47        |\n",
      "|    ep_rew_mean          | 0.295       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014671741 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.0668      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.881       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.23        |\n",
      "|    ep_rew_mean          | 0.156       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014657306 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.069       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.83        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.99        |\n",
      "|    ep_rew_mean          | 0.316       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014537811 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.0779      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.868       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 2.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.33        |\n",
      "|    ep_rew_mean          | 0.316       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015424651 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.44       |\n",
      "|    explained_variance   | 0.0645      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.17        |\n",
      "|    ep_rew_mean          | 0.357       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 348         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017465165 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 0.0998      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.901       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while check_bt_training_status():\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfc3e14a-b0a1-42ee-a2bd-d5570812ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save learned model\n",
    "if modelname: torch.save(agent.model.policy.state_dict(),'./saved_models/'+modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef67d33-a9b8-45a4-b303-9ec012e0b7ed",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d14a0e6-68cd-41e9-b3c8-7edac5134871",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not script:\n",
    "    import pandas as pd\n",
    "    df=pd.read_csv('/tmp/aiagents.monitor.csv',comment='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eeceeac-034d-42dc-bc16-f57e7aa21d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>index=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472
         ],
         "xaxis": "x",
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          7.204275900000001,
          8.7690402,
          9.9681928,
          8.820526399999999,
          7.269770600000001,
          8.157696099999999,
          9.158525899999999,
          8.870033099999999,
          8.4871132,
          5.036676599999999,
          5.176451599999999,
          3.7102582999999996,
          1.0902194999999995,
          -0.5735163000000008,
          0.7302661999999994,
          -1.6138739000000004,
          0.27078679999999966,
          -4.063439700000001,
          -2.5262225000000003,
          -3.464386,
          -6.612208900000001,
          -8.165517000000001,
          -10.5841147,
          -6.2693593000000005,
          -9.2572182,
          -9.5685785,
          -11.474689399999999,
          -8.9069632,
          -8.489218699999999,
          -5.0142323,
          -4.6860618,
          -5.4981632000000005,
          -4.64147,
          -7.373279200000001,
          -5.4885981,
          -4.4112867,
          -0.41516620000000015,
          -0.5933906000000001,
          -3.2194468,
          -5.3344059999999995,
          -4.260054,
          -1.9649746999999997,
          2.5405777,
          4.9671644,
          4.4240620999999996,
          4.867409100000001,
          2.4138836,
          4.4531114,
          8.0073951,
          8.1979089,
          8.785769400000001,
          12.0447733,
          9.508719600000001,
          7.885705400000001,
          10.7393642,
          11.589337700000002,
          13.736156099999999,
          13.9287916,
          13.5924681,
          15.0852347,
          15.1040603,
          15.121556100000001,
          17.815929,
          21.5886098,
          21.343870799999998,
          19.3323808,
          19.5305649,
          20.202284100000004,
          17.6026761,
          17.762947599999997,
          19.134538499999998,
          16.8864732,
          14.798950099999999,
          10.128018299999999,
          9.469727699999998,
          10.965844899999999,
          11.960166300000001,
          10.1283416,
          8.651056,
          6.387905900000002,
          9.1937634,
          8.8093906,
          10.065273300000001,
          14.089530400000001,
          11.0772498,
          13.67061,
          11.479969800000001,
          14.4719042,
          15.739278199999998,
          16.9155899,
          11.8172998,
          6.831945500000001,
          3.2973498,
          3.8728027000000003,
          6.8322083000000005,
          6.8730042,
          10.2716543,
          10.113958899999998,
          14.0022794,
          15.954107200000001,
          20.0749177,
          27.6114077,
          32.6673703,
          28.893260899999994,
          29.0469084,
          29.135858599999995,
          26.415662500000003,
          24.684548200000002,
          23.455472699999998,
          24.2845024,
          27.4766069,
          25.767875800000002,
          23.7658171,
          25.1171886,
          23.9279286,
          22.9575607,
          24.7283973,
          26.8850413,
          25.164109699999997,
          22.867656500000002,
          18.3808242,
          17.2963198,
          17.9482779,
          19.8294155,
          21.1519831,
          21.452885900000002,
          20.7848637,
          20.504737,
          23.4501765,
          22.879023999999998,
          24.928994699999997,
          22.296169499999998,
          24.181611,
          25.3556289,
          26.651473799999998,
          25.667254499999995,
          26.8434988,
          26.3963865,
          25.62551,
          29.663566799999995,
          28.1052046,
          30.525697399999995,
          29.662365899999998,
          27.7485949,
          26.372230899999998,
          28.2206584,
          27.5497835,
          27.4627817,
          27.0555639,
          27.379762999999997,
          29.455154399999998,
          31.750107300000003,
          35.057423799999995,
          36.099750199999995,
          38.263084299999996,
          36.8150216,
          38.2866208,
          36.8118717,
          37.6910448,
          36.5606241,
          34.522770599999994,
          34.4986787,
          33.071184800000005,
          33.1978282,
          33.2512964,
          35.6711225,
          34.4767125,
          38.4400114,
          40.2025821,
          40.903533700000004,
          43.65837,
          45.4616635,
          45.2534455,
          45.7900331,
          45.710136999999996,
          44.5076805,
          44.5726531,
          42.7603635,
          42.392954399999994,
          41.4607864,
          37.926702399999996,
          35.9212125,
          37.7727595,
          36.6245202,
          37.081019399999995,
          38.56150409999999,
          40.4146221,
          39.5497461,
          39.9211861,
          40.9983776,
          43.3946149,
          47.932705,
          46.8864728,
          50.4679008,
          51.099233600000005,
          52.602537299999995,
          49.624718099999996,
          49.258965,
          49.0756067,
          48.0532675,
          49.72746289999999,
          47.0380696,
          46.7183213,
          47.260252200000004,
          46.3206262,
          46.034147000000004,
          47.61486609999999,
          48.8474423,
          49.352829199999995,
          51.2606679,
          50.8557575,
          52.70610909999999,
          53.91649279999999,
          51.1284461,
          52.0046777,
          50.4968749,
          53.1048725,
          54.54041159999999,
          55.3736368,
          55.562762799999994,
          55.517080799999995,
          56.06591639999999,
          56.9197065,
          59.16518659999999,
          58.96977489999999,
          59.06827969999999,
          54.807863,
          54.9401313,
          52.6307834,
          51.17714529999999,
          52.14403,
          49.9688814,
          43.366305,
          40.196639899999994,
          40.3158814,
          40.3284326,
          43.7150807,
          44.3141575,
          46.5768711,
          45.040284299999996,
          46.0295047,
          45.51240489999999,
          49.4278157,
          51.85920259999999,
          52.2908762,
          54.0841189,
          51.9295628,
          52.99342420000001,
          52.9362433,
          55.65802649999999,
          52.50673969999999,
          55.694005600000004,
          55.874416399999994,
          55.9422726,
          55.71222730000001,
          54.8826102,
          57.7951046,
          57.5796212,
          57.3105752,
          56.87654249999999,
          60.5515259,
          56.313602700000004,
          57.1163589,
          57.3871934,
          56.2327138,
          57.75754489999999,
          58.2570565,
          57.559885799999996,
          56.651234599999995,
          57.75524729999999,
          56.98216599999999,
          61.357967699999996,
          61.90855259999999,
          62.141490499999996,
          63.63283160000001,
          62.8711751,
          62.7355707,
          62.2269419,
          62.120223599999996,
          62.0775709,
          59.7394675,
          55.597853099999995,
          53.9761553,
          52.7650699,
          53.94749939999999,
          54.130863399999996,
          54.063700600000004,
          52.1749776,
          53.5551646,
          54.3146857,
          57.4513458,
          58.5868387,
          59.604846499999994,
          61.110461,
          60.115264100000005,
          60.1947383,
          60.79956990000001,
          60.9397023,
          62.09482549999999,
          61.6265787,
          60.1324263,
          61.1923326,
          61.992326500000004,
          61.096920699999984,
          60.0681425,
          61.596369,
          60.2149869,
          61.5179472,
          60.020132799999985,
          60.315290899999994,
          61.787647400000004,
          61.439678300000004,
          60.631675599999994,
          60.285443799999996,
          59.3720575,
          57.04033449999999,
          59.2578307,
          62.2713892,
          64.5571571,
          63.3995619,
          63.18476009999999,
          64.8852454,
          65.87238899999998,
          66.9738301,
          69.96502139999998,
          72.0600298,
          70.5260874,
          68.97259009999999,
          67.7740196,
          68.32059849999999,
          68.06685039999999,
          66.1317208,
          67.47447389999999,
          67.65198869999999,
          66.50235669999999,
          66.68620469999999,
          68.8438285,
          70.06783629999998,
          71.5665707,
          70.95321009999999,
          69.52846960000001,
          72.89533099999998,
          71.6356553,
          70.3240279,
          71.06394499999999,
          70.26389959999999,
          68.70356,
          67.92051459999999,
          67.0504395,
          68.4559122,
          71.6539133,
          70.96444979999998,
          70.5567535,
          71.60940989999999,
          70.7491198,
          71.75788989999998,
          70.38099009999999,
          69.52869569999999,
          70.7175475,
          71.02384430000001,
          68.3796107,
          68.4947007,
          68.3191369,
          68.4459644,
          69.3658873,
          66.3304902,
          66.2851266,
          65.6775754,
          63.9890715,
          62.54261799999999,
          63.325764400000004,
          63.151019399999996,
          64.76538009999999,
          61.451885399999995,
          61.370458899999996,
          62.7996318,
          64.5872088,
          67.14367569999999,
          67.00809339999999,
          68.7585021,
          69.65139509999999,
          69.1727128,
          70.35755400000001,
          74.6621628,
          72.5802306,
          72.8121046,
          71.00363,
          69.5742918,
          69.3728154,
          68.65305409999999,
          66.1541264,
          65.4758732,
          64.4164436,
          61.806067399999996,
          63.468451200000004,
          64.495261,
          64.4480279,
          64.9149033,
          66.981055,
          67.40063089999998,
          69.7681715,
          71.7365192,
          70.6013419,
          69.8227317,
          70.9048083,
          68.4946925,
          68.6160333,
          67.7396913,
          67.39511990000001,
          67.2603932,
          67.2623374,
          64.7447896,
          65.8548113,
          69.27750019999999,
          68.47037309999999,
          70.86520970000001,
          71.9961347,
          72.8186808,
          69.4420527,
          68.8452352,
          67.48252719999999,
          68.42397609999999,
          67.97554059999999,
          66.9650325,
          64.8627013,
          63.6280866,
          63.3235374,
          61.0536853,
          63.986213799999994,
          64.7900121,
          66.0745458,
          66.4631229,
          66.16717329999999,
          67.5167578,
          69.31098010000001,
          70.9123325,
          71.5685778,
          73.603554,
          74.8878407,
          73.2037048,
          73.9406129,
          73.14354039999999,
          73.5157998,
          73.6022864,
          73.5400781,
          72.7511848,
          72.4580734,
          73.1327183,
          70.6095545,
          71.7419385,
          71.3633689,
          72.2624549,
          72.25608309999998,
          70.2264364,
          70.7314435,
          70.5559634,
          70.1630997,
          70.2257343,
          71.6724088,
          71.78415399999999,
          70.2337482,
          71.6294049,
          72.6487258,
          72.7960623,
          73.33603989999999,
          73.0807873,
          72.7842967,
          71.5622984,
          71.3930038,
          72.65117919999999,
          74.574681,
          72.26207699999999,
          70.833012,
          72.6440428,
          73.01993630000001,
          74.7961466,
          77.3749253,
          78.3348689,
          77.7612857,
          77.35562089999999,
          75.7105077,
          77.14061769999999,
          77.7847922,
          75.498005,
          75.1061665,
          73.89197659999999,
          72.5439872,
          71.6683645,
          73.4349574,
          73.2548829,
          74.2185145,
          72.5523961,
          71.57224579999999,
          70.86795,
          71.4572179,
          72.189648,
          70.5631618,
          72.4053413,
          70.8090138,
          71.133871,
          70.9937343,
          73.2072406,
          73.7603561,
          77.4931312,
          77.3675796,
          74.311964,
          75.1505544,
          73.928519,
          73.28858269999999,
          73.435335,
          74.68619240000001,
          74.8958884,
          75.1078635,
          73.9345818,
          72.3750353,
          74.1381041,
          76.30047299999998,
          76.3036096,
          76.73224880000001,
          76.6317223,
          74.20638039999999,
          69.7392134,
          70.29056419999999,
          69.2470888,
          69.19807239999999,
          69.5535432,
          67.65864459999999,
          68.054112,
          66.75603299999999,
          66.82424219999999,
          68.57003619999999,
          70.0786779,
          69.89890779999999,
          69.37347759999999,
          69.6321395,
          70.36604519999999,
          70.2376072,
          69.6646375,
          70.8828971,
          68.7132159,
          68.5187329,
          69.7476397,
          69.8343006,
          70.7943625,
          72.26682079999999,
          72.6459614,
          73.87372819999999,
          75.00872939999999,
          75.4945887,
          77.158232,
          77.0465929,
          78.6112377,
          77.70498009999999,
          77.77975439999999,
          76.83614130000001,
          75.7015722,
          74.67540389999999,
          74.61156349999999,
          73.76549689999999,
          73.3416632,
          72.8181243,
          70.8770121,
          72.5052887,
          73.5734745,
          73.38015069999999,
          74.7497886,
          76.4399716,
          76.3381976,
          78.1798432,
          78.325151,
          80.44259279999999,
          81.6288541,
          81.4882298,
          81.4105561,
          82.7167205,
          82.1274395,
          79.5415211,
          79.56955980000001,
          77.8274294,
          79.03258679999999,
          77.04677439999999,
          78.5293588,
          77.9423728,
          76.4334454,
          75.503315,
          74.2046112,
          76.17399470000001,
          74.54931020000001,
          75.48157899999998,
          74.09099610000001,
          74.5831306,
          73.2689761,
          72.6049366,
          73.21719399999999,
          72.1542451,
          73.86834719999999,
          73.21415479999999,
          75.16209319999999,
          75.0647211,
          74.40596989999999,
          75.49396399999999,
          75.99895939999999,
          76.37289229999999,
          75.4792702,
          78.13280449999999,
          77.8977058,
          77.90120999999999,
          77.6100456,
          78.4091516,
          80.6374214,
          79.6124633,
          80.0205107,
          78.57391150000001,
          79.138314,
          78.38202349999999,
          78.4297511,
          78.0182392,
          78.4063387,
          77.4273285,
          75.8217196,
          75.963149,
          74.64005089999999,
          75.4022023,
          74.5181795,
          73.4448189,
          72.4742493,
          73.7613351,
          73.2868524,
          73.71956730000001,
          74.4055554,
          74.16259210000001,
          74.83310850000001,
          75.7176442,
          77.15448669999999,
          78.6948288,
          78.4618371,
          76.9469731,
          76.1269897,
          76.4817571,
          75.01775549999999,
          75.824331,
          74.7704298,
          74.9931697,
          73.83347180000001,
          73.46186589999999,
          75.16900989999999,
          75.2212926,
          75.40876929999999,
          75.69039190000001,
          76.1424074,
          77.0741177,
          78.091171,
          77.7571207,
          78.5967311,
          78.4634147,
          78.2335768,
          78.972976,
          78.905864,
          77.25573069999999,
          78.0222187,
          76.1980922,
          76.4852094,
          77.21701379999999,
          76.957725,
          76.6579244,
          76.3382979,
          76.8330069,
          76.8058367,
          78.75772450000001,
          79.752657,
          80.149435,
          78.6352945,
          77.2782204,
          78.0229081,
          78.20749249999999,
          77.77765259999998,
          77.5107348,
          78.2010303,
          77.69101559999999,
          77.44801329999999,
          78.0788222,
          76.50187389999999,
          77.36389369999999,
          78.1024874,
          78.00447079999999,
          76.9734471,
          77.4453513,
          77.24754979999999,
          76.3034993,
          76.4661666,
          75.1129612,
          76.6195105,
          75.388987,
          73.3267856,
          73.48845539999999,
          74.847846,
          72.78750690000001,
          73.54756119999999,
          74.92844439999999,
          75.1246405,
          74.9298318,
          76.0732965,
          77.4012778,
          78.1923966,
          78.9242082,
          79.3179752,
          80.9616824,
          79.9481828,
          79.4739172,
          78.9823588,
          79.7406375,
          81.01616620000001,
          80.8804272,
          81.1983012,
          80.8881399,
          79.31320480000001,
          79.9684403,
          81.3854302,
          81.04860529999999,
          80.7491263,
          80.7482689,
          80.8261717,
          80.63526110000001,
          80.8252015,
          79.8379873,
          81.2408993,
          81.3765064,
          80.33026749999999,
          81.0643313,
          81.42320079999999,
          81.5925594,
          79.5773485,
          78.87006389999999,
          79.1718099,
          79.2263466,
          79.49387529999998,
          79.28997530000001,
          79.23746159999999,
          77.5181538,
          76.9273068,
          77.1412512,
          78.03341379999999,
          78.5586448,
          78.4879419,
          78.7708845,
          78.17781289999999,
          77.3713732,
          77.7293004,
          79.4304157,
          80.3753108,
          80.5924335,
          81.6156086,
          81.5938795,
          82.7857781,
          83.6319338,
          83.1711776,
          84.1512309,
          83.29185770000001,
          83.92334020000001,
          83.32847009999999,
          82.4595958,
          80.7485187,
          82.45426230000001,
          82.1047833,
          80.27521329999999,
          81.2759042,
          78.8792424,
          79.08976679999999,
          77.28241519999999,
          77.19069449999999,
          77.0695178,
          77.6252112,
          75.81169209999999,
          75.54373480000001,
          76.7580199,
          75.9163278,
          78.45150149999999,
          79.1669763,
          80.7744405,
          81.69004249999999,
          82.41775879999999,
          83.1771056,
          84.0829158,
          83.9674469,
          83.81679729999999,
          85.0570512,
          82.566321,
          82.3294373,
          82.1315416,
          81.53757329999999,
          81.5168638,
          79.9078682,
          80.184547,
          80.3871293,
          80.5639917,
          80.0191926,
          81.4736983,
          82.58244729999998,
          81.612712,
          82.0273,
          81.9905024,
          83.34081269999999,
          82.037914,
          81.9546975,
          82.0653061,
          80.9936376,
          80.51106009999998,
          79.7325615,
          80.2867084,
          80.0783401,
          80.0580305,
          80.15377579999999,
          81.1476901,
          81.0381436,
          80.7580127,
          81.575695,
          81.72263579999999,
          81.67904689999999,
          82.0298923,
          81.8579563,
          82.995508,
          82.91939219999999,
          81.9285198,
          82.1387441,
          82.5898179,
          82.5196426,
          82.72262559999999,
          82.51055219999999,
          82.4609643,
          82.1541149,
          81.51153509999999,
          81.50037289999999,
          82.03001079999999,
          80.28346930000001,
          79.2034491,
          78.3340293,
          79.3876108,
          79.59626169999999,
          79.2680053,
          79.74007529999999,
          79.2183867,
          78.9260205,
          79.5573688,
          79.2400778,
          79.6955505,
          81.5860092,
          79.8720688,
          79.93369390000001,
          80.7732513,
          81.32050569999998,
          82.4810071,
          82.8458799,
          82.6806235,
          83.9832394,
          84.6173548,
          84.51398549999999,
          86.0336235,
          86.6020381,
          86.17790149999999,
          85.2304293,
          84.7162818,
          84.4937046,
          83.7996706,
          83.94782330000001,
          84.1263546,
          82.65935979999999,
          82.9790741,
          83.4028103,
          83.43791619999999,
          83.75916529999999,
          83.622754,
          84.2754592,
          85.2564429,
          84.9439206,
          85.26829319999999,
          86.1241655,
          85.15386649999999,
          83.5420198,
          83.5916176,
          83.2580519,
          83.92021629999999,
          83.3524699,
          81.51192189999999,
          81.3800629,
          79.270768,
          79.6149537,
          79.35767899999999,
          79.9856455,
          80.1213481,
          79.8806482,
          78.5752166,
          78.434562,
          80.3339785,
          80.91772639999999,
          82.4463214,
          81.5527189,
          81.76224429999999,
          80.91864319999999,
          81.2333753,
          81.9612918,
          81.25447849999999,
          80.81088170000001,
          80.8104779,
          80.6668028,
          80.54453509999999,
          80.9644328,
          81.12742279999999,
          81.2462844,
          81.0946414,
          81.1355564,
          82.53689469999999,
          83.02822330000001,
          82.24795189999999,
          83.4088204,
          84.0943272,
          84.3575825,
          85.10496760000001,
          86.1789066,
          85.9669217,
          85.6245545,
          84.3029457,
          84.5337016,
          85.56251239999999,
          84.8753084,
          83.7194593,
          83.3284989,
          83.7949173,
          84.0368259,
          83.5696318,
          84.5069291,
          85.5402527,
          84.79718249999999,
          82.8533663,
          82.0806857,
          82.63211820000001,
          83.0940662,
          83.2894128,
          83.062893,
          82.677279,
          82.42487930000001,
          83.3306578,
          83.5712215,
          84.9669576,
          85.5974636,
          85.1906587,
          84.96592559999999,
          84.9122233,
          84.5452051,
          85.7428592,
          84.88041489999999,
          83.4166457,
          83.5023488,
          83.7286441,
          82.756742,
          82.3993119,
          82.67540220000001,
          80.2138502,
          80.8640437,
          80.66252870000001,
          80.3436566,
          80.64323099999999,
          81.1593348,
          79.9132089,
          80.276884,
          81.1278579,
          81.5527802,
          82.90743219999999,
          81.602104,
          80.4017398,
          81.3822502,
          81.81820909999999,
          80.8059993,
          81.6602224,
          82.2554177,
          81.822727,
          81.8269307,
          82.6924282,
          82.27151749999999,
          82.9893409,
          83.28750679999999,
          83.78540430000001,
          84.19393889999999,
          83.75837379999999,
          83.06206829999999,
          80.7584641,
          79.8523005,
          79.5971271,
          81.0437646,
          81.54918649999999,
          79.84059160000001,
          79.3585111,
          80.30702819999999,
          80.88198299999999,
          81.54016929999999,
          84.10759870000001,
          85.2056015,
          84.3172734,
          82.7978611,
          80.2691858,
          80.9068686,
          80.5332482,
          80.0258533,
          78.93059550000001,
          78.9541151,
          78.8725753,
          77.22264429999998,
          77.8213943,
          77.7493846,
          79.0626529,
          79.794832,
          79.96751929999999,
          79.12709939999999,
          80.48495929999999,
          79.9546564,
          80.3541859,
          81.44153839999998,
          81.09843359999999,
          82.8846353,
          83.6967097,
          83.4380003,
          83.5936703,
          83.9287267,
          83.51966159999999,
          83.99516550000001,
          84.1576154,
          83.65794489999999,
          83.53561249999998,
          83.3770123,
          83.3178733,
          82.9394145,
          82.9022454,
          82.70448339999999,
          82.51454650000001,
          82.5027739,
          82.3440008,
          83.0555857,
          83.91525479999999,
          83.3534632,
          83.42917709999999,
          83.3497619,
          83.3213663,
          83.8037181,
          83.43471,
          83.9745119,
          83.9094756,
          84.1617972,
          84.2961268,
          84.3000317,
          84.2265194,
          84.98040519999999,
          84.34776969999999,
          84.0959476,
          84.3710562,
          83.5154217,
          83.638911,
          82.297866,
          81.2712875,
          81.51929229999999,
          81.3371542,
          81.71183429999999,
          82.0986453,
          82.00991,
          82.8185994,
          83.6748264,
          83.0816005,
          84.1842312,
          85.0763221,
          85.2530884,
          85.34086909999999,
          84.7256944,
          85.8774178,
          86.7658283,
          86.4659858,
          86.23010599999999,
          87.1405479,
          87.517329,
          86.4293806,
          85.9613669,
          86.6215468,
          87.3091891,
          86.63406319999999,
          86.1610783,
          86.8777231,
          86.4711268,
          85.8892374,
          85.16179699999999,
          85.7208338,
          86.2312348,
          85.77401259999999,
          85.6369467,
          85.5820768,
          86.5803128,
          86.64460879999999,
          86.5801931,
          86.8323711,
          87.32841409999999,
          86.82842409999999,
          86.2647187,
          85.93531999999999,
          85.9116232,
          86.59921239999998,
          86.3172754,
          85.8630938,
          85.89840670000001,
          86.3520234,
          86.36631829999999,
          87.5481762,
          87.64747109999999,
          87.99451250000001,
          87.48423799999999,
          86.6330351,
          85.5050854,
          84.04801069999999,
          83.9798221,
          83.30763390000001,
          81.9715315,
          81.49538629999999,
          82.29264090000001,
          82.1244112,
          82.1646199,
          82.5860035,
          82.9847582,
          83.61120349999999,
          84.5746782,
          83.65854119999999,
          84.7974371,
          85.1542783,
          84.8073806,
          85.5445772,
          84.8011324,
          84.02837559999999,
          84.47007909999999,
          85.3479169,
          84.96682469999999,
          85.98601749999999,
          85.66346549999999,
          84.83385259999999,
          84.7241653,
          82.7819967,
          84.01682699999999,
          84.237179,
          84.95341260000001,
          84.16500429999999,
          84.47738949999999,
          83.937276,
          84.25874019999999,
          84.72270999999999,
          83.4478645,
          84.66682,
          84.09021720000001,
          84.6059927,
          83.8357288,
          84.8215876,
          84.9095478,
          85.1628681,
          84.89173410000001,
          84.1204837,
          84.6029706,
          84.9454729,
          84.82395389999999,
          84.7638684,
          85.20326229999999,
          85.3041559,
          84.24445119999999,
          84.5483007,
          84.6478538,
          85.1918725,
          86.3713425,
          85.98036379999999,
          85.2951854,
          85.83788999999999,
          85.8319602,
          85.3996918,
          85.6412593,
          85.6380449,
          85.1544961,
          85.9564365,
          85.03653669999998,
          85.4537963,
          87.0590447,
          85.58678309999999,
          84.68315809999999,
          85.1008574,
          84.6158234,
          85.0159118,
          85.04552269999999,
          84.5397151,
          84.69686979999999,
          84.3494503,
          83.3689338,
          83.2698137,
          83.6296976,
          83.05356259999999,
          84.2891588,
          84.0365301,
          84.7468342,
          84.9037282,
          84.90353019999999,
          85.2600882,
          85.38807039999999,
          86.2100074,
          86.0052511,
          86.4371852,
          85.6416143,
          85.3039775,
          85.59783540000001,
          85.8817559,
          85.98005679999999,
          86.0985421,
          85.9822545,
          86.1503358,
          86.82646559999999,
          86.2088662,
          86.423642,
          87.50294099999999,
          86.98869359999999,
          85.69114809999999,
          86.0824282,
          85.5016555,
          86.22681589999999,
          86.18823359999999,
          85.2019814,
          85.19858880000001,
          85.69094429999998,
          84.0419234,
          84.27584859999999,
          85.5956013,
          85.43750179999999,
          85.8265392,
          85.58568009999999,
          85.27000790000001,
          86.204215,
          85.8340638,
          85.50896379999999,
          86.24132619999999,
          85.7282265,
          85.36738829999999,
          84.982464,
          84.7987083,
          85.1702906,
          85.4677789,
          85.33956719999999,
          86.4872348,
          86.2986536,
          85.7640633,
          86.14269099999999,
          85.97998329999999,
          86.549429,
          86.8280604,
          86.7591557,
          85.8705226,
          86.19557499999999,
          86.0699147,
          85.9564547,
          85.9881782,
          86.28324289999999,
          86.6879591,
          86.96656949999999,
          86.6805821,
          86.91134170000001,
          87.9115002,
          87.9132065,
          87.4160138,
          88.0772786,
          88.04067819999999,
          87.4092545,
          86.9087729,
          87.2939022,
          87.80526239999999,
          87.47356579999999,
          87.4635175,
          86.6847722,
          85.4596988,
          85.43802099999999,
          85.7491485,
          85.0809933,
          84.5400113,
          84.0842262,
          82.655713,
          82.1922819,
          81.5173762,
          81.3979274,
          82.32170699999999,
          82.35765459999999,
          82.645414,
          83.91194190000002,
          84.3934382,
          83.7503735,
          84.4753821,
          84.9143409,
          84.5916778,
          83.8639039,
          84.723869,
          84.58308149999999,
          84.4735178,
          84.4672096,
          83.4114529,
          83.4905669,
          82.9995455,
          82.12496110000001,
          83.337357,
          83.4266126,
          82.060794,
          81.0283956,
          80.9069243,
          80.8468309,
          81.9709203,
          82.27380360000001,
          82.9746636,
          83.6333195,
          82.2838633,
          81.9929517,
          82.98642149999999,
          82.8052575,
          83.05073949999999,
          82.5762062,
          81.8732721,
          81.1848759,
          81.066502,
          80.4946215,
          81.6056035,
          82.5132888,
          82.0830693,
          83.44310300000001,
          82.7853955,
          83.15320299999999,
          84.5802692,
          84.4115361,
          84.3896844,
          84.5932823,
          83.4611203,
          84.37943720000001,
          84.11173299999999,
          84.1472419,
          84.95268639999999,
          84.66339559999999,
          84.01659599999999,
          84.58230119999999,
          84.92080289999998,
          84.20895909999999,
          85.2242933,
          84.46616509999998,
          85.3504789,
          84.4248959,
          84.59198109999998,
          85.1949576,
          85.49751710000001,
          85.89821219999999,
          86.06158830000001,
          87.4887004,
          87.2811268,
          87.1646006,
          86.525226,
          87.3062099,
          86.77974099999999,
          85.86445359999999,
          85.8091549,
          86.15824109999998,
          85.4949556,
          85.2654446,
          84.7207735,
          85.220422,
          85.6232388,
          84.4842535,
          84.6904873,
          84.7519855,
          84.4900126,
          83.06399719999999,
          82.968755,
          82.3278407,
          82.9839415,
          83.3299287,
          82.867955,
          83.8800331,
          83.3892631,
          83.1702793,
          82.8768518,
          84.1931782,
          85.1262832,
          85.3976429,
          84.9748075,
          84.9258815,
          85.66496409999999,
          84.7794693,
          85.63719809999999,
          85.9923234,
          86.15499919999999,
          85.5532667,
          84.58083789999999,
          84.2857338,
          84.7093848,
          83.4426172,
          81.4845541,
          82.02042409999999,
          81.9197016,
          82.4518208,
          82.9231258,
          83.42181869999999,
          83.4912371,
          84.15726149999999,
          83.9478498,
          83.856911,
          85.4980334,
          84.67871599999998,
          84.187691,
          82.57579679999999,
          81.4829916,
          81.1197537,
          81.08867210000001,
          79.97347470000001,
          79.30942209999999,
          78.9026332,
          79.2650083,
          79.6559944,
          79.5840877,
          80.639979,
          81.053744,
          80.6289361,
          80.7592046,
          81.06723819999999,
          81.2889553,
          81.7173521,
          81.98654199999999,
          82.4539571,
          82.890684,
          82.1956458,
          81.80519050000001,
          82.2866545,
          82.19370699999999,
          82.93481349999999,
          83.0860262,
          84.0581136,
          83.0176161,
          82.8529587,
          82.5464312,
          82.6232578,
          82.1743698,
          82.36503809999999,
          82.745498,
          82.6105091,
          82.42769419999999,
          81.4658349,
          81.60714089999999,
          80.97982579999999,
          81.1193581,
          81.5924459,
          82.51175839999999,
          82.01413649999999,
          81.1380097,
          80.1635258,
          81.22892970000001,
          81.22847859999999,
          81.6605877,
          82.1046076,
          82.28036990000001,
          81.73713819999999,
          81.38708059999999,
          81.8112422,
          81.78072039999999,
          82.3396367,
          81.1741622,
          81.6696205,
          81.8229702,
          81.01327599999999
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not script:\n",
    "    import plotly.express as px\n",
    "    px.line(df['r'].rolling(window=10).mean().values).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414322c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metarl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5008e426caa1f5e2a3cabb61a0a32dd514aa39ff1b51b49a9d39831a35b7d2d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
